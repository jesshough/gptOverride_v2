# ChatGPT Override Project

### Overview & Goal:
This project aims to create an enhancement in GPT capabilities by providing the ability to override responses when they are contextually inaccurate. The goal is to provide a solution for situations where a user's input context may be open to interpretation, potentially resulting in responses from GPT that are ambiguous, misleading, or contextually incorrect. 

### Use Case Example:
A company employee asks GPT questions about an internal tool, only to receive a response regarding an external tool GPT found online that happened to have the same name.

### Project Goals:
- Develop an ML model that analyzes ChatGPT's responses and provides overrides when necessary. _(should this be in the form of a suggestion or should it just make a call?)_
- Incorporate contextual understanding and field-specific knowledge to enhance GPT's NL processing abilities.
- Design a user-friendly interface/integration mechanism for users to leverage within ChatGPT's response generation pipeline. _(can I call GPT from my own code/website? What options do I have for this?)_
- Validate the effectiveness of the override system through thorough testing.

### Purpose:
The use of AI conversation agents is increasing in various fields, commonly in the forms of customer support, virtual assistance, and knowledge management. While GPT provides impressive responses, it may occasionally produce ones that are contextually incorrect or irrelevant, leading to user frustration or misinformation. By developing a system to override GPT's responses when necessary, we can improve the overall user experience and trustworthiness of AI-driven conversational platforms.

### Contributors:
- Dev: Jess Houghton
- Mentor: Mark Farra

